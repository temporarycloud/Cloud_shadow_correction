{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RFZUYWXxYTle"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Here you can find image shadow generation functions, along with the declaration and compilation of the U-Net model\n",
        "def load_images_from_folder(folder, indices):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        if not filename.endswith(\"_radiance.tif\"):\n",
        "            print(\"Invalid filename format:\", filename)\n",
        "            continue\n",
        "        image_index = filename.split('_')[-2]\n",
        "        if int(image_index) not in indices:\n",
        "           continue\n",
        "        img = cv2.imread(os.path.join(folder, filename),cv2.IMREAD_UNCHANGED)\n",
        "        if img is not None:\n",
        "            img = (img / 1000).astype('float32')\n",
        "            images.append(img)\n",
        "            print(\"Loaded image:\", filename)\n",
        "    return  np.array(images)\n",
        "\n",
        "\n",
        "def resize_images(images, target_size=(128, 128)):\n",
        "    return np.array([cv2.resize(img, target_size) for img in images])\n",
        "\n",
        "def uneven_illumination(image, max_illumination=1.2, min_illumination=-0.5, smoothness=75):\n",
        "    image = image.astype(float)\n",
        "    rows, cols = image.shape[:2]\n",
        "    gradient_type = np.random.choice(['linear', 'circular', 'diagonal'])\n",
        "\n",
        "    if gradient_type == 'linear':\n",
        "        start, end = np.random.randint(0, cols, 2)\n",
        "        start, end = min(start, end), max(start, end)\n",
        "        mask = np.ones((rows, cols))\n",
        "        mask[:, start:end] = np.linspace(min_illumination, max_illumination, end - start).reshape(1, -1)\n",
        "    elif gradient_type == 'circular':\n",
        "        center = [np.random.randint(low=0, high=rows), np.random.randint(low=0, high=cols)]\n",
        "        mask = np.zeros((rows, cols))\n",
        "        max_distance_to_center = max(np.sqrt((rows - center[0]) ** 2 + (cols - center[1]) ** 2), np.sqrt(center[0] ** 2 + center[1] ** 2))\n",
        "        for i in range(rows):\n",
        "            for j in range(cols):\n",
        "                distance_to_center = np.sqrt((i - center[0]) ** 2 + (j - center[1]) ** 2)\n",
        "                mask[i, j] = min_illumination + (max_illumination - min_illumination) * (distance_to_center / max_distance_to_center)\n",
        "    elif gradient_type == 'diagonal':\n",
        "        mask = np.zeros((rows, cols))\n",
        "        diagonal_start = np.random.choice(['top_left', 'top_right', 'bottom_left', 'bottom_right'])\n",
        "        for i in range(rows):\n",
        "            for j in range(cols):\n",
        "                if diagonal_start == 'top_left':\n",
        "                    mask[i, j] = min_illumination + (max_illumination - min_illumination) * ((i + j) / (rows + cols - 2))\n",
        "                elif diagonal_start == 'top_right':\n",
        "                    mask[i, j] = min_illumination + (max_illumination - min_illumination) * ((i + (cols - j)) / (rows + cols - 2))\n",
        "                elif diagonal_start == 'bottom_left':\n",
        "                    mask[i, j] = min_illumination + (max_illumination - min_illumination) * (((rows - i) + j) / (rows + cols - 2))\n",
        "                elif diagonal_start == 'bottom_right':\n",
        "                    mask[i, j] = min_illumination + (max_illumination - min_illumination) * (((rows - i) + (cols - j)) / (rows + cols - 2))\n",
        "\n",
        "    mask = cv2.GaussianBlur(mask, (smoothness, smoothness), 0)\n",
        "\n",
        "\n",
        "    image_masked = cv2.multiply(image, mask)\n",
        "    return image_masked, mask\n",
        "\n",
        "def generate_noisy_images_and_masks(images,num_samples=1500):\n",
        "    noisy_images = []\n",
        "    illumination_masks = []\n",
        "    original_indices = []\n",
        "    for idx, img in enumerate(images):\n",
        "        for _ in range(num_samples):\n",
        "            max_illumination = np.random.uniform(0.7, 2)\n",
        "            min_illumination = np.random.uniform(-0.5, max_illumination)\n",
        "            noisy_image, illumination_mask = uneven_illumination(img, max_illumination, min_illumination)\n",
        "\n",
        "            noisy_images.append(noisy_image)\n",
        "            illumination_masks.append(illumination_mask)\n",
        "            original_indices.append(idx)\n",
        "\n",
        "    return np.array(noisy_images), np.array(illumination_masks), np.array(original_indices)\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "def unet_model(input_size=(128, 128, 1)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.001))(inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.001))(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.001))(pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.001))(pool3)\n",
        "\n",
        "    up1 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv4))\n",
        "    merge1 = concatenate([conv3, up1], axis=3)\n",
        "    conv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge1)\n",
        "\n",
        "    up2 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv5))\n",
        "    merge2 = concatenate([conv2, up2], axis=3)\n",
        "    conv6 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge2)\n",
        "\n",
        "    up3 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\n",
        "    merge3 = concatenate([conv1, up3], axis=3)\n",
        "    conv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge3)\n",
        "\n",
        "    conv8 = Conv2D(1, 1)(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv8)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "mainout=\"/content\"\n",
        "collection = \"/content\" #change this too\n",
        "folder=\"/content\"#change this too\n",
        "\n",
        "collection_path =mainout+collection+folder\n",
        "if not os.path.exists(collection_path):\n",
        "    os.makedirs(collection_path)\n",
        "    print(f\"Created collection directory: {collection_path}\")\n",
        "else:\n",
        "    print(f\"Collection directory already exists: {collection_path}\")\n",
        "folder_path = os.path.join(collection_path, folder)\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "    print(f\"Created folder directory: {folder_path}\")\n",
        "else:\n",
        "    print(f\"Folder directory already exists: {folder_path}\")\n",
        "\n",
        "indices = [2]\n",
        "#indices = [5]\n",
        "# you can run several models given the image name has an indice\n",
        "#In the case of the Miacasense Red-edge sensor, each individual band is numbered 1 to 5\n",
        "model = unet_model()\n",
        "model.compile(optimizer=Adam(lr=1e-4), loss='MeanSquaredError', metrics=['MAE'])\n",
        "\n",
        "early_stopping = EarlyStopping(patience=15, verbose=1)\n",
        "\n",
        "for index in indices:\n",
        "    x_train = load_images_from_folder('/content', [index])\n",
        "    x_train = resize_images(x_train)\n",
        "\n",
        "    x_train_noisy, x_train_masks, original_indices = generate_noisy_images_and_masks(x_train, num_samples=1500)\n",
        "\n",
        "    x_train_noisy, x_test_noisy, x_train_masks, x_test_masks, train_indices, test_indices = train_test_split(\n",
        "        x_train_noisy, x_train_masks, original_indices, test_size=0.1)\n",
        "\n",
        "    x_train = x_train[train_indices]\n",
        "    x_test = x_train[test_indices]\n",
        "\n",
        "    x_train_noisy = x_train_noisy[..., np.newaxis]\n",
        "    x_test_noisy = x_test_noisy[..., np.newaxis]\n",
        "    x_train_masks = x_train_masks[..., np.newaxis]\n",
        "    x_test_masks = x_test_masks[..., np.newaxis]\n",
        "\n",
        "    current_x_train_noisy = x_train_noisy\n",
        "    current_x_train_masks = x_train_masks\n",
        "    current_x_test_noisy = x_test_noisy\n",
        "    current_x_test_masks = x_test_masks\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint(os.path.join(collection_path, f'unet_index_{index}.hdf5'),\n",
        "                                   monitor='loss', verbose=1, save_best_only=True)\n",
        "    time.sleep(8)\n",
        "    model.fit(x_train_noisy, x_train_masks,\n",
        "              epochs=25,\n",
        "              batch_size=32,\n",
        "              shuffle=True,\n",
        "              callbacks=[model_checkpoint, early_stopping],\n",
        "              validation_data=(x_test_noisy, x_test_masks))\n",
        "    del x_train\n",
        "    del x_train_noisy\n",
        "    del x_train_masks\n",
        "    del x_test_noisy\n",
        "    del x_test_masks\n",
        "    del train_indices\n",
        "    del test_indices\n",
        "    del current_x_train_noisy\n",
        "    del current_x_train_masks\n",
        "    del current_x_test_noisy\n",
        "    del current_x_test_masks\n",
        "    del model_checkpoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PNhgTZfYWGi",
        "outputId": "6eb73b0a-8563-4c5a-859e-89e9e0c18d24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created collection directory: /content/content/content\n",
            "Folder directory already exists: /content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid filename format: .config\n",
            "Invalid filename format: .ipynb_checkpoints\n",
            "Invalid filename format: content\n",
            "Loaded image: IMG_0458_2_radiance.tif\n",
            "Invalid filename format: sample_data\n",
            "Epoch 1/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 5.8611 - MAE: 0.5373\n",
            "Epoch 1: loss improved from inf to 5.86107, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 53s 643ms/step - loss: 5.8611 - MAE: 0.5373 - val_loss: 1.4678 - val_MAE: 0.1348\n",
            "Epoch 2/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43/43 [==============================] - ETA: 0s - loss: 1.3672 - MAE: 0.1173\n",
            "Epoch 2: loss improved from 5.86107 to 1.36723, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 394ms/step - loss: 1.3672 - MAE: 0.1173 - val_loss: 1.2761 - val_MAE: 0.0850\n",
            "Epoch 3/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 1.2243 - MAE: 0.0789\n",
            "Epoch 3: loss improved from 1.36723 to 1.22426, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 386ms/step - loss: 1.2243 - MAE: 0.0789 - val_loss: 1.1757 - val_MAE: 0.0802\n",
            "Epoch 4/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 1.1336 - MAE: 0.0465\n",
            "Epoch 4: loss improved from 1.22426 to 1.13360, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 16s 384ms/step - loss: 1.1336 - MAE: 0.0465 - val_loss: 1.0984 - val_MAE: 0.0549\n",
            "Epoch 5/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 1.0721 - MAE: 0.0577\n",
            "Epoch 5: loss improved from 1.13360 to 1.07206, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 386ms/step - loss: 1.0721 - MAE: 0.0577 - val_loss: 1.0406 - val_MAE: 0.0406\n",
            "Epoch 6/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 1.0176 - MAE: 0.0397\n",
            "Epoch 6: loss improved from 1.07206 to 1.01759, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 385ms/step - loss: 1.0176 - MAE: 0.0397 - val_loss: 0.9933 - val_MAE: 0.0365\n",
            "Epoch 7/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.9775 - MAE: 0.0594\n",
            "Epoch 7: loss improved from 1.01759 to 0.97749, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 387ms/step - loss: 0.9775 - MAE: 0.0594 - val_loss: 0.9664 - val_MAE: 0.1116\n",
            "Epoch 8/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.9374 - MAE: 0.0380\n",
            "Epoch 8: loss improved from 0.97749 to 0.93737, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 388ms/step - loss: 0.9374 - MAE: 0.0380 - val_loss: 0.9181 - val_MAE: 0.0239\n",
            "Epoch 9/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.9041 - MAE: 0.0376\n",
            "Epoch 9: loss improved from 0.93737 to 0.90415, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 16s 384ms/step - loss: 0.9041 - MAE: 0.0376 - val_loss: 0.8956 - val_MAE: 0.0896\n",
            "Epoch 10/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.8759 - MAE: 0.0424\n",
            "Epoch 10: loss improved from 0.90415 to 0.87591, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 16s 383ms/step - loss: 0.8759 - MAE: 0.0424 - val_loss: 0.8603 - val_MAE: 0.0345\n",
            "Epoch 11/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.8471 - MAE: 0.0253\n",
            "Epoch 11: loss improved from 0.87591 to 0.84714, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 387ms/step - loss: 0.8471 - MAE: 0.0253 - val_loss: 0.8338 - val_MAE: 0.0207\n",
            "Epoch 12/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.8265 - MAE: 0.0507\n",
            "Epoch 12: loss improved from 0.84714 to 0.82653, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 385ms/step - loss: 0.8265 - MAE: 0.0507 - val_loss: 0.8122 - val_MAE: 0.0338\n",
            "Epoch 13/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.8015 - MAE: 0.0330\n",
            "Epoch 13: loss improved from 0.82653 to 0.80149, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 386ms/step - loss: 0.8015 - MAE: 0.0330 - val_loss: 0.7896 - val_MAE: 0.0263\n",
            "Epoch 14/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.7804 - MAE: 0.0324\n",
            "Epoch 14: loss improved from 0.80149 to 0.78043, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 386ms/step - loss: 0.7804 - MAE: 0.0324 - val_loss: 0.7733 - val_MAE: 0.0646\n",
            "Epoch 15/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.7614 - MAE: 0.0380\n",
            "Epoch 15: loss improved from 0.78043 to 0.76144, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 387ms/step - loss: 0.7614 - MAE: 0.0380 - val_loss: 0.7501 - val_MAE: 0.0205\n",
            "Epoch 16/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.7420 - MAE: 0.0268\n",
            "Epoch 16: loss improved from 0.76144 to 0.74204, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 385ms/step - loss: 0.7420 - MAE: 0.0268 - val_loss: 0.7400 - val_MAE: 0.0766\n",
            "Epoch 17/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.7276 - MAE: 0.0455\n",
            "Epoch 17: loss improved from 0.74204 to 0.72757, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 388ms/step - loss: 0.7276 - MAE: 0.0455 - val_loss: 0.7162 - val_MAE: 0.0248\n",
            "Epoch 18/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.7083 - MAE: 0.0257\n",
            "Epoch 18: loss improved from 0.72757 to 0.70835, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 385ms/step - loss: 0.7083 - MAE: 0.0257 - val_loss: 0.7167 - val_MAE: 0.1229\n",
            "Epoch 19/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.6937 - MAE: 0.0354\n",
            "Epoch 19: loss improved from 0.70835 to 0.69367, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 16s 383ms/step - loss: 0.6937 - MAE: 0.0354 - val_loss: 0.6842 - val_MAE: 0.0175\n",
            "Epoch 20/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.6771 - MAE: 0.0206\n",
            "Epoch 20: loss improved from 0.69367 to 0.67714, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 384ms/step - loss: 0.6771 - MAE: 0.0206 - val_loss: 0.6694 - val_MAE: 0.0167\n",
            "Epoch 21/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.6799 - MAE: 0.0876\n",
            "Epoch 21: loss did not improve from 0.67714\n",
            "43/43 [==============================] - 16s 379ms/step - loss: 0.6799 - MAE: 0.0876 - val_loss: 0.6845 - val_MAE: 0.1310\n",
            "Epoch 22/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.6594 - MAE: 0.0620\n",
            "Epoch 22: loss improved from 0.67714 to 0.65937, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 388ms/step - loss: 0.6594 - MAE: 0.0620 - val_loss: 0.6466 - val_MAE: 0.0354\n",
            "Epoch 23/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.6388 - MAE: 0.0251\n",
            "Epoch 23: loss improved from 0.65937 to 0.63879, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 16s 383ms/step - loss: 0.6388 - MAE: 0.0251 - val_loss: 0.6322 - val_MAE: 0.0334\n",
            "Epoch 24/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.6252 - MAE: 0.0245\n",
            "Epoch 24: loss improved from 0.63879 to 0.62524, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 17s 385ms/step - loss: 0.6252 - MAE: 0.0245 - val_loss: 0.6185 - val_MAE: 0.0228\n",
            "Epoch 25/25\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.6124 - MAE: 0.0214\n",
            "Epoch 25: loss improved from 0.62524 to 0.61241, saving model to /content/content/content/unet_index_2.hdf5\n",
            "43/43 [==============================] - 16s 383ms/step - loss: 0.6124 - MAE: 0.0214 - val_loss: 0.6061 - val_MAE: 0.0219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#process and save several images\n",
        "\n",
        "def process_and_save_images(input_folder, output_folder, model):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.tif'):\n",
        "            img_path = os.path.join(input_folder, filename)\n",
        "\n",
        "            original_image = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "            img = original_image.astype('float32') / 1000\n",
        "\n",
        "            target_size = (128, 128)\n",
        "            img_resized = cv2.resize(img, target_size)\n",
        "\n",
        "            img_resized = img_resized[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "            predicted_mask = model.predict(img_resized)\n",
        "\n",
        "            predicted_mask = np.squeeze(predicted_mask)\n",
        "\n",
        "            predicted_mask_resized = cv2.resize(predicted_mask, (original_image.shape[1], original_image.shape[0]))\n",
        "\n",
        "            corrected_image = original_image / predicted_mask_resized\n",
        "\n",
        "            output_filename = os.path.splitext(filename)[0] + '_corrected.tif'\n",
        "            output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "            cv2.imwrite(output_path, corrected_image.astype('uint16'))\n",
        "\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.imshow(predicted_mask_resized, cmap='gray')\n",
        "            plt.title('Predicted Mask')\n",
        "            plt.show()\n",
        "\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.imshow(corrected_image, cmap='gray')\n",
        "            plt.title('Corrected Image')\n",
        "            plt.show()\n",
        "\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.imshow(original_image, cmap='gray')\n",
        "            plt.title('Original Image')\n",
        "            plt.show()\n",
        "\n",
        "input_folder = '/content/To_correct'\n",
        "output_folder = '/content/corrected'\n",
        "\n",
        "process_and_save_images(input_folder,output_folder, model)"
      ],
      "metadata": {
        "id": "esR7BE6-bG6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}