{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksU_jpBCWmHi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Uneven illumination generator\n",
        "# Just add any RGB image to the content folder (One or multiple)\n",
        "\n",
        "def resize_images(images, target_size=(128, 128)):\n",
        "    return np.array([cv2.resize(img, target_size) for img in images])\n",
        "\n",
        "def uneven_illumination_rgb(image, max_illumination=1.0, min_illumination=0.5, smoothness=75):\n",
        "    image = image.astype(float)\n",
        "    rows, cols = image.shape[:2]\n",
        "    gradient_type = np.random.choice(['linear', 'circular', 'diagonal'])\n",
        "\n",
        "    mask = np.zeros((rows, cols))\n",
        "\n",
        "    if gradient_type == 'linear':\n",
        "        start, end = np.random.randint(0, cols, 2)\n",
        "        start, end = min(start, end), max(start, end)\n",
        "        mask[:, start:end] = np.linspace(min_illumination, max_illumination, end - start).reshape(1, -1)\n",
        "    elif gradient_type == 'circular':\n",
        "        center = [np.random.randint(low=0, high=rows), np.random.randint(low=0, high=cols)]\n",
        "        max_distance_to_center = max(np.sqrt((rows - center[0])**2 + (cols - center[1])**2),\n",
        "                                     np.sqrt(center[0]**2 + center[1]**2))\n",
        "        for i in range(rows):\n",
        "            for j in range(cols):\n",
        "                distance_to_center = np.sqrt((i - center[0])**2 + (j - center[1])**2)\n",
        "                mask[i, j] = min_illumination + (max_illumination - min_illumination) * (distance_to_center / max_distance_to_center)\n",
        "    elif gradient_type == 'diagonal':\n",
        "        diagonal_start = np.random.choice(['top_left', 'top_right', 'bottom_left', 'bottom_right'])\n",
        "        for i in range(rows):\n",
        "            for j in range(cols):\n",
        "                if diagonal_start == 'top_left':\n",
        "                    mask[i, j] = min_illumination + (max_illumination - min_illumination) * ((i + j) / (rows + cols - 2))\n",
        "                elif diagonal_start == 'top_right':\n",
        "                    mask[i, j] = min_illumination + (max_illumination - min_illumination) * ((i + (cols - j)) / (rows + cols - 2))\n",
        "                elif diagonal_start == 'bottom_left':\n",
        "                    mask[i, j] = min_illumination + (max_illumination - min_illumination) * (((rows - i) + j) / (rows + cols - 2))\n",
        "                elif diagonal_start == 'bottom_right':\n",
        "                    mask[i, j] = min_illumination + (max_illumination - min_illumination) * (((rows - i) + (cols - j)) / (rows + cols - 2))\n",
        "\n",
        "    mask = cv2.GaussianBlur(mask, (smoothness, smoothness), 0)\n",
        "\n",
        "    image_masked = np.zeros_like(image)\n",
        "    for c in range(3):\n",
        "        image_masked[:, :, c] = cv2.multiply(image[:, :, c], mask)\n",
        "\n",
        "    return image_masked, mask\n",
        "\n",
        "\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_UNCHANGED)\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = img.astype('float32') / 255\n",
        "            images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "def resize_images(images, target_size=(128, 128)):\n",
        "    return np.array([cv2.resize(img, target_size, interpolation=cv2.INTER_AREA) for img in images])\n",
        "\n",
        "def generate_noisy_images(images, num_samples=1500):\n",
        "    noisy_images = []\n",
        "    illumination_masks = []\n",
        "    for image in images:\n",
        "        for _ in range(num_samples):\n",
        "            max_illumination = np.random.uniform(0.7, 1.0)\n",
        "            min_illumination = np.random.uniform(0.1, max_illumination)\n",
        "            noisy_image, illumination_mask = uneven_illumination_rgb(image, max_illumination, min_illumination)\n",
        "            noisy_images.append(noisy_image)\n",
        "            illumination_masks.append(illumination_mask)\n",
        "    return np.array(noisy_images), np.array(illumination_masks)\n",
        "\n",
        "folder_path = '/content'\n",
        "x_train = load_images_from_folder(folder_path)\n",
        "x_train = resize_images(x_train)\n",
        "\n",
        "x_train_noisy, x_train_masks = generate_noisy_images(x_train,num_samples=1500)\n",
        "num_samples_per_image = len(x_train_noisy) // len(x_train)\n",
        "x_train_repeated = np.repeat(x_train, num_samples_per_image, axis=0)\n",
        "\n",
        "x_train, x_test, x_train_noisy, x_test_noisy, x_train_masks, x_test_masks = train_test_split(\n",
        " x_train_repeated, x_train_noisy, x_train_masks, test_size=0.1, random_state=42)\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(x_train[0])\n",
        "plt.title(\"Original Image\")\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(x_train_noisy[0])\n",
        "plt.title(\"Noisy Image\")\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(x_train_masks[0], cmap='gray')\n",
        "plt.title(\"Illumination Mask\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#plotting 10 examples\n",
        "n = min(10, len(x_train_noisy), len(x_train_masks))\n",
        "\n",
        "plt.figure(figsize=(15, n * 4))\n",
        "for idx in range(n):\n",
        "    ax = plt.subplot(n, 3, idx * 3 + 1)\n",
        "    plt.imshow(x_train[idx])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    ax = plt.subplot(n, 3, idx * 3 + 2)\n",
        "    plt.imshow(x_train_noisy[idx])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    ax = plt.subplot(n, 3, idx * 3 + 3)\n",
        "    plt.imshow(x_train_masks[idx], cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0VQl14KlW3hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def unet_model(input_size=(128, 128, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.001))(inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.001))(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.001))(pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.001))(pool3)\n",
        "\n",
        "    up1 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv4))\n",
        "    merge1 = concatenate([conv3, up1], axis=3)\n",
        "    conv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge1)\n",
        "\n",
        "    up2 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv5))\n",
        "    merge2 = concatenate([conv2, up2], axis=3)\n",
        "    conv6 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge2)\n",
        "\n",
        "    up3 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\n",
        "    merge3 = concatenate([conv1, up3], axis=3)\n",
        "    conv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge3)\n",
        "\n",
        "    conv8 = Conv2D(1, 1)(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv8)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = unet_model()\n",
        "ModelCheckpoint.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), loss='MeanSquaredError', metrics=['MAE'])\n",
        "\n",
        "early_stopping = EarlyStopping(patience=15, verbose=1)\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('unet_FLirduo_proR_RGB.hdf5', monitor='loss', verbose=1, save_best_only=True)\n",
        "model.fit(x_train_noisy , x_train_masks,\n",
        "          epochs=25,\n",
        "          batch_size=32,\n",
        "          shuffle=True,\n",
        "          callbacks=[model_checkpoint, early_stopping],\n",
        "          validation_data=(x_test_noisy, x_test_masks))"
      ],
      "metadata": {
        "id": "ozoUwAjKW7WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mport os\n",
        "import cv2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "def process_and_correct_images(folder_path):\n",
        "    corrected_folder_path = os.path.join(folder_path, 'corrected')\n",
        "\n",
        "    if not os.path.exists(corrected_folder_path):\n",
        "        os.makedirs(corrected_folder_path)\n",
        "        print(f\"Created directory: {corrected_folder_path}\")\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith('.jpg'):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "            if img is None:\n",
        "                print(f\"Failed to load image: {img_path}\")\n",
        "                continue\n",
        "\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            original_size = img.shape[:2]\n",
        "\n",
        "            img_resized = cv2.resize(img, (128, 128))\n",
        "            img_resized = img_resized[np.newaxis, ...] / 255.0\n",
        "\n",
        "            predicted_mask = model_RGB.predict(img_resized)\n",
        "            predicted_mask = np.squeeze(predicted_mask)\n",
        "\n",
        "            predicted_mask_resized = cv2.resize(predicted_mask, (original_size[1], original_size[0]))\n",
        "\n",
        "            corrected_image = np.zeros_like(img, dtype=np.float32)\n",
        "            for c in range(3):\n",
        "                corrected_image[..., c] = img[..., c] / predicted_mask_resized\n",
        "\n",
        "\n",
        "            new_filename = filename[:-4] + '_corrected.jpg'\n",
        "            save_path = os.path.join(corrected_folder_path, new_filename)\n",
        "\n",
        "            cv2.imwrite(save_path, cv2.cvtColor(corrected_image, cv2.COLOR_RGB2BGR))\n",
        "            print(f\"Corrected image saved to: {save_path}\")\n",
        "\n",
        "# Specify the directory containing the JPEG images to be corrected\n",
        "folder_path = \"/content\"\n",
        "process_and_correct_images(folder_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "i2nzTObHYt_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}